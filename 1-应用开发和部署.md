## 应用开发和部署

### 使用牲口模式

将需要大量、精心工作来维护的具有特定属性的服务实例（宠物模式），转变为可以被随时销毁和被替换的服务实例组（牲口模式），从而将更多资源和精力投入到更有价值的地方。配合自动化的基础设施，使服务实例以更快的速度演进，也使业务具备更多的弹性去应对市场变化。

为大家所熟知的“无状态”应用，是“牲口模式”的一种实现方式。“牲口模式”不等于“无状态”。

#### 优点：

1. 支持自动故障切换。配合自动化基础设施，无需单独管理每个服务实例，节约管理成本和团队精力。
2. 支持自动水平伸缩（Scale-Out），配合自动化基础设施，从容应对业务峰谷，节约业务成本。
3. 支持随时被销毁或被替换，可以在不影响服务稳定性的前提下部署应用、进行系统升级或者打补丁。

#### 缺点：

1. 需要单独管理每一个服务实例，可能是手动安装、调试。
2. 服务实例只能垂直扩展（Scale-Up），昂贵且容易遇到瓶颈。
3. 应用部署笨重，难以自由地升级或者回滚应用，从而阻碍业务频繁变更。
4. 难以及时给服务实例打补丁、升级系统，从而承担不必要的安全风险。
5. 难以避免故障带来的服务失效和可能存在的数据损失的风险。

#### 如何实施：

1. API请求之间完全隔离，完成业务所需的数据均由客户端发送的请求提供。

2. 使用客户端Cookie、cache取代服务器端Session。对于一些敏感的临时数据，服务器端可以加密后交由客户端存储，在下个API请求时发回服务器解密使用。

3. 通过锁或者幂等性设计，使得应用能正确、快速、自动地解决对同一份数据的竞争而导致的流程异常、数据不一致等问题。例如，定时任务批量读取数据。

### 使业务升级向前兼容

向前兼容指低版本的系统、程序或技术能优雅处理（例如：忽略其不理解的部分）高版本的系统、程序或技术。向前兼容技术的目标是让旧设备能够识别为新设备生成的数据。

简单的说就是旧版本的系统可以接受新版本的数据，是旧版本对新版本的兼容。

在做业务升级时候，设计你的业务具有向前兼容的能力，以应对升级失败时某一功能模块或者依赖无法随之回滚的风险。比如说在有数据库字段变化的升级中，在正式对数据库做变动之前，基于旧的业务流程做代码层面更新，使其可以兼容数据库将要发生的改动并加以部署。在数据库升级完成之后，如果新的业务流程上线后不幸出现重大的问题等情况需要回滚时，回滚之后的代码仍然可以兼容数据库的变化，而不用对数据库也进行回滚。

#### 优点：

1. 支持安全、快速回滚：保持向前兼容意味着，当新版本出现问题需要回滚的时候，可以安全快速当回滚到旧的版本。哪怕整个系统有‘不可回滚’的部分，那也只是部分‘不可回滚’，不必考虑其他费力措施解决完全不可回滚的问题。
2. 简化发布，持续升级：业务升级向前兼容意味着升级不再令人望而生畏，而是可以‘轻松写意’的。虽然持续升级是一个系统的工程实践，不单单指升级版本，还包括为了预防升级版本给质量带来风险而采取的其他措施，比如自动化测试的持续构建，持续集成流水线的构建等，但是向前兼容使得部署可以安全，回滚可以快速，服务一直在线，收益远大于问题。

#### 缺点：

1. 设计成本：要做到兼容未来的变化。这听起来就很难。一开始很难获知所有用例、极端案例和业务理解。回顾过去并说这是一个错误的决定很容易，今天做出明天不会后悔的决定要困难得多。
2. 开发成本：需要在代码中增加复杂性，这些复杂性可能并不是实现现实业务逻辑必须的，继而给现有系统功能的可靠性带来间接影响。

#### 如何实施：

1. select语句只获取需要的字段，避免使用`select * from`语句，有效防止新增字段对应用逻辑的影响，还能减少对性能的影响。

2. 只新增接口，对现有接口不能做任何修改，同时可感知到的默认行为都要保持不变。

3. 如需修改接口，通过在接口上增加版本号。

4. 数据库表结构变更通过新增字段实现。

5. 给新增字段提供默认值。比如shell脚本新增一个输入变量，提供默认值。脚本类似如下获取输入：
   
   ```
   NEW_VARIABLE=${NEW_VARIABLE:-DEFAULT_VALUE}
   ```

6. APP提供强制更新功能。

### 使用唯一性标识给镜像打标签

当生成容器镜像时，应当使用唯一性标识来给容器镜像打标签，唯一标识可以更好的标记当次生成的镜像，避免出现多个同名标签但不同的版本镜像被使用的情况。例如多次部署都使用了latest标签的镜像，可能因为拉取和缓存策略导致不同节点使用了不同版本的镜像，从而导致功能上的不一致，在这种情况下，并不能很方便的判断出某个节点部署的是哪一个版本。

唯一标识最好有一定的含义，不仅可以用来区分产物，还可以获取到本次构建的关键信息。比如git提交哈希等关联性比较强的标识。虽然时间戳也是一个唯一性比较强的标识，但是关联性相对较差，如果长度不足，也有一定的几率产生碰撞。可以考虑使用组合型标签，比如使用时间戳，build号，版本号等根据自己的需求来组合生成唯一标识，这样的标签本身就包含了很丰富的信息。

不建议单纯使用pipeline的build序号来作为镜像的标签，如果需要更换CI工具或者重建pipeline时，这个序号将会被重置而可能产生重复，除非在构建脚本中加入偏移量。而且不同的CI工具获取这个序号的方法也有所不同，对于迁移并不友好。虽然它的可追溯性看起来较好，但是单纯的Build序号和代码之间并没有直接的关联。

如果不是需要对外公开发布的镜像，并不建议对同一镜像打上多个不同标签。因为绝大部分的情况下，我们只会选用其中一个的标签在所有的地方使用，多个标签的实际意义并不会很大。

如果制品库支持immutable特性，强烈建议开启这个功能，防止因为意外情况导致对已上传的镜像的覆盖。

#### 优点：

1. 可以准确对应的到源代码具体版本，在溯源时可以对应到特定的提交而不是可能存在的多个提交。

2. 不需要使用SHA256等额外的信息来区分同一标签的不同版本。

#### 缺点：

1. 一些类型的唯一性标识可读性不是很高，比如git提交哈希。

2. 一些类型的标识受时间影响，不能使用同一命令获得一致结果，需要使用其他的方式来传递给后续阶段，比如时间戳。

3. 制品库immutable功能开启之后，重跑已完成构建镜像的pipeline会发生上传镜像失败的错误，有可能会导致后续任务不能继续。

#### 如何实施：

```
GIT_HASH=$(git rev-parse HEAD)

docker build --rm -t "myapp:${GIT_HASH}" .
```

### 使用同一个构建产物部署多个环境

应该在不同环境中使用相同的构建产物来部署，不要重新构建，这样来保证部署在不同环境中的应用代码是被验证代码。例如本次构建的产物，在开发环境部署后经由开发或测试人员以及相关的自动化测试工具完成相关的测试后，如果没有问题可以部署到后面环境，此时应该继续使用该产物部署后面的环境，不可重新构建产物来做后面环境的部署，不可覆盖该产物标识。因为即便是同一份源代码，由于其依赖以及构建环境的不同，甚至因为不同时间由于外部依赖的更新，都可能会使构建出来的产物出现差异，从而导致非预期的情况出现。

#### 优点：

1. 确保所有的环境部署的构建产物是一致的。
2. 确保部署到生产环境的产物是测试验证之后并无变化的。

#### 缺点：

1. 对于前端类纯静态资源的应用，针对不同环境，由于需要连接不同的后端服务地址，因此无法直接使用唯一的构建产物。针对这种情况可以考虑在部署或启动阶段，配合传入环境变量或参数，用一些额外的启动脚本来修改配置文件，从而达到所有环境使用同一个构建产物。
   
   比如可以在使用了nginx作为image的容器镜像里，可以在CMD指令里面先执行一段脚本来对配置等进行修改，然后再启动nginx进程

       示例，容器运行时会根据具体部署的环境传入环境变量WEB_ENV的值

```
FROM nginx:1.21.3-alpine

COPY dist /app/

CMD sed -i -e "s/VUE_APP_ENV/$WEB_ENV/g" /app/env-config.js \
  && nginx -g 'daemon off;'
```

2. 对于移动端app，也存在与前端应用类似的问题，由于app运行时无法得知自己运行的环境上下文，因此一般只能为多个环境构建多个产物。

#### 如何实施：

1. 在设计CICD流水线时，将构建产物同步到产物仓库时，给该产物打上唯一标识。

2. 将该唯一标识传递到在后面所有的部署流水线任务中，所有的部署任务都使用该唯一标识所指向的构建产物。

3. 如果需要在多个制品库保存构建产物，最好做一次完整性检查。

### 减少脚本/工具对环境的依赖

一般情况下，脚本都会或多或少的使用到一些外部工具。而我们的脚本很有可能会运行在不同的环境中，不同环境中提供的工具也会有版本和用法的差异。我们建议尽可能的减少所使用的工具对环境的依赖，尤其是系统不会默认安装的工具。另外在编写脚本的时候，也尽量避免使用只有某些版本才有的语法特性。这些情况都会导致管理脚本有可能出现一些不可预期的结果，我们建议使用容器化工具或者容器化环境管理工具如Batect来替代对应的需求。

#### 优点：

1. 环境中只需要安装容器化工具即可。如：docker
   
    软件构建过程中可能会存在不同的服务需求不同，特别在微服务架构中。如前端使用 nodejs 开发，后端使用 java。则需要在 agent 中安装对应的编译软件，无疑增加了工具数量以及版本的维护成本。使用容器化工具的方式来管理，我们只需要确保 agent 有容器运行时，并将这个 image 做好保存，以后无论是前端还是后端，我们都能通过脚本来运行不同的容器工具如 gradle 镜像，就可以进行软件构建。使用这种方法，容器运行时的版本更新也可以做到一步到位。

2. 使本地运行与在线上环境中运行的软件一致，都是基于同一个 Dockerfile 或者同一个 image
   
    使用容器化的方式基于同一个 Dockerfile 构建出来的 artifact，我们可以将它运行在本地进行测试，通过后用同样的的 artifact 部署到线上环境。这样我们的安全测试以及业务测试结果都能进行保证。出现问题也可以使用本地的环境进行快速的排查，这样可以在一些权限控制严格，没有线上环境 debug 权限的情况下，进行一个快速的查错。

3. 对新人友好
   
    容器化的工具使得新人只需要知道进行构建的软件使用方式，不需要再去手动安装，配置工具。新人如果需要更新工具或者版本，可以快速的进行，无需关心每个工具的安装，升级方式，同时也避免了手动操作过程中出现的失误来 block CI 的运行。

4. 升级单个项目的环境变得非常容易
   
    使用容器化工具的情况下，脚本可以作为一个构建阶段的文档。通过统一的管理可以清除的知道在一个干净的环境中运行了哪些工具来完成构建工作。每个工具的版本信息，来源信息在一个脚本中就可以看到。当有升级需求的时候，可以快速的更改，无需关心工具背后的依赖问题，简单查看工具容器的文档，更改本版号就可以完成升级来进行测试。脚本在版本控制之下，测试失败回滚的代价也极小。

5. 解耦对 CI 工具或 agent 的依赖
   
    虽然在实际项目中我们更换CI工具的情况极少，但是如果做到使用容器化工具来进行软件的构建，我们的脚本就可以在不同的agent中来运行构建，将极大的减少维护成本，增加 agent 的利用率。不用再去手动维护每个 agent 的配置，只需要有相同的容器运行时配置，即可增强构建阶段的兼容性。由于使用容器，所以在真的发生 CI 工具切换的时候，我们也只需要使新的工具能运行脚本，agent 支持容器运行时，即可开始构建，大大减少了切换工具的额外工作量。

#### 缺点：

1. 需要花费更多的流量
   
    由于在 agent 上没有安装构建所需要的各种软件，只有容器化工具(docker 等)，每次在运行任何的一条命令的时候都需要去容器仓库中获取对应的镜像。这无疑增加了 agent 在流量上的压力。

2. 运行过程需要的时间更长
   
    由于在 agent 上没有安装构建所需要的各种软件，每当要运行一个 task，都需要在 agent 上启动一个容器去运行对应，那么时间就会变为：下载 image + 启动容器 + task 执行，相比于直接在 agent 上直接运行 task 多出了“下载 image + 启动容器”的时间。

#### 如何实施：

例：在容器中运行 terraform

在使用 terraform 时，不同版本之间的 terraform 并不兼容，那么如何保证所有人与 CI 都使用相同的 terraform 版本就是一个非常麻烦的事情。那么如果我们无论在 CI 还是本地都基于 docker 去运行 terraform 就可以解决这个问题。

```shell
#!/usr/bin/env bash

function terraform() {
  docker run --rm -it \
      -v $(pwd):/app -w /app \
      hashicorp/terraform:1.1.4 -c "$@"
}

terraform init
terraform plan && terraform apply
```

### 及时更新容器的基础镜像

基础镜像是业务镜像的地基，其包含了我们业务和应用所必需的基础库、二进制文件和配置文件。一个良好维护的基础镜像通常会根据需要做更新，这些更新通常包含安全补丁，新功能或对操作系统或框架的改进等，我们建议你及时的更新容器的基础镜像来保障业务的安全性。除非有特定原因需要继续使用旧版本镜像，否则都建议使用最新的镜像。

#### 优点：

1. 最新的镜像通常带有可以增强应用程序安全性的补丁修复
2. 最新的镜像通常包括可以提高应用程序性能的新功能或改进功能

#### 缺点：

1. 新功能可能存在不可预期的bug
2. 新的功能有非常小的概率存在未知的安全漏洞，如果有特殊的安全需求，请在安全部门的指导下升级

#### 如何实施：

在通过CI打包创建应用容器镜像时，可以通过指定Dockerfile中基础镜像的唯一标识来指定基础镜像的版本。当官方镜像推出新版本时，唯一标识将会改变，通过更新唯一标识将基础镜像指向最新版本。
我们可以使用dfresh来检查和更新基础镜像。

* 检查基础镜像是否有更新
  
  ```
  $ dfresh check Dockerfile
  Dockerfile:1: mysql
  old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
  new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd
  ```

* 更新基础镜像
  
  ```
  $ dfresh update Dockerfile
  Dockerfile:1: mysql
  old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
  new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd
  ```

* 回退方法
    在遇到由于新基础镜像问题，需要回退基础镜像版本的情况时，将Dockerfile中基础镜像的SHA256改为上一个所使用的版本。

### 定期检查和升级依赖包

随着 Bug 修复、新功能的开发或者其他更新，我们应用的依赖包可能会过时。此时应用的依赖项越多，就越难跟上这些更新。过时的依赖包可能对安全构成威胁，并对性能产生负面影响。最新的软件包可防止漏洞，这意味着定期的依赖性检查和更新很重要。我们建议定期的对应用的依赖包做更新和安全检查，并升级到一个合适的版本。并且我们建议在应用的 pipeline 中加入这些检查任务，并在常规的开发过程中及时发现和升级。如果应用已经处于维护阶段，我们也建议定期执行这些检查并在需要的时候加以升级。

#### 优点:

1. 定期升级依赖可以让应用的安全性和代码的可用性都有保障。  
2. 定期升级依赖会让解决依赖版本冲突和代码兼容性变得容易。  
3. 更新依赖项可以获得新的依赖项版本提供的所有性能改进。 这些改进可以有多种形式，例如修复以前的性能问题、改进了实现和算法等。  
4. 升级依赖项不仅可以改进现有功能，还可以使用到以前不存在的新功能。这些新功能最终可能让我们更好的实现自己应用的新功能。

#### 缺点:

1. 如果不及时更新依赖，将会使得产品难以维护，并可能导致开发人员的时间被常规的、无意义的工作占用。
2. 如果长期不更新依赖，会使应用面临无人问津的风险，之后在某一天需要进行改动的时候，面临大量的依赖包过期无法获取和版本升级造成的接口变化。这时就需要投入非常高的成本来让代码重新变得可用，甚至完全无法更新而变成遗留系统。
3. 当进行大的版本升级时，需要对应用程序进行更多的更改才能与较新的库兼容。这使得付出代价比及时更新依赖大得多。
4. 如果忽略升级依赖项，那么会面临无法在自己喜欢的平台上运行软件的可能。 例如，如果停止升级软件中的数据库驱动程序，那么将无法使用旧版本的数据库系统。这不仅会使应用变得过时且易受攻击，而且甚至可能无法从该数据库系统提供商处获得任何支持。  
5. 如果应用依赖于过时的依赖项而导致升级困难变得很难维护，会使得项目很难找到对这些旧技术有经验的人，甚至失去现有的维护者。

#### 如何实施:

##### 1. 手动检查

###### JS 篇

* npm-outdated & npm-update 
  
  * npm outdated：可以使用 `npm outdated` 获取当前需要升级的包的信息。
  * npm update: 会把所有的包升级到我们定义的需要的版本号。如果需要升级到最新的则需要使用@latest eg: `npm update cypress@latest`。

* npm-check-updates: 是一种更高级的检查工具
  
  * 首先需要全局安装 npm-check-updates: `npm install -g npm-check-updates `；
  * ncu: 检查需要升级的包信息，这里类似 `npm outdated`；
  * ncu --upgrade/ncu -u: 将所有的包升级到最新版本，即便是包含重大更改，也会进行更新。注意：更新完成后不会自动运行 npm install，所以还需要再手动执行来更新 package-lock.json。
  * ncu --interactive/ncu -i : interactive mode 安装某个包。
  
  小结：`npm-outdated` 和 `npm-check-updates`都可以用来做 `JS`项目的包检查、升级。

###### Java 篇

* 在 build.gradle中配置 `owasp.dependency-check`
* 执行` ./gradlew dependencyCheckAnalyze`
* 查看报告： `项目根目录>build>reports>dependency-check-report.html `

##### 2. CI Pipeline 集成

* npm-check-updates 与 Buildkite Pipeline 的集成
  
   由于 buildkite 没有官方插件支持 dependency-check。所以对于buildkite 推荐两种方式：
  
  * 自己开发对应功能的插件，然后集成到 pipeline 的 step 中；
  
  * 通过 docker-compose 的方式去运行对应的检查，将其在 pipeline 的 step 中去运行（如果需要可以添加 block 来强制检查 npm-check-updates 的结果）。
    
    ```
    ## Dockerfile
    FROM node:18.7.0
    WORKDIR app
    COPY ["package.json", "package-lock.json*", "./"]
    RUN npm install -g npm-check-updates
    ```
    
    ```
    ## docker-compose
    version: "2"
    
    services:
    node-version-check:
      build: .
      command: sh -c "ncu"
    ```
    
    ```
    ## auto/dependency-check.sh
    #!/usr/bin/env bash
    
    set -ex
    docker-compose run --rm node-version-check
    ```
    
    ```
    ## buildkite script
    steps
     - label: 'node version dependency-check'
       command: auto/dependency-check.sh
       agents:
         queue: 'xxxx'
    
     -  block: 'Please check node-version-check'
    ```

* jenkins pipeline 的集成：需要安装 dependency-check Plugin。步骤如下：
  
  1. 在 Jenkins Global Tool Configuration 安装 dependency-check；
  2. 在 Jenkins builder 配置已经安装好的 dependency-check；
  3. 在 Jenkins Publish 里配置读取 dependency-check 的 report ，通过对相关指标进行读取，设置阈值，配置构建失败或者警告等设置。

##### 3. 工具集成检查

如果项目 code 托管在 Github，我们可以使用 Dependabot 和 Renovate 工具和 Github 集成来做依赖检查。这两个工具都会做定期扫描，创建依赖版本升级的 PR。

###### 配置 Dependabot 进行版本更新

* 在 GitHub 的代码仓库的主页,找到代码仓库名称下的 `setting`；
* 在边栏的`安全性`部分中，单击`代码安全性和分析`；
* 在`代码安全和分析`下，在`Dependabot version updates`右侧，单击`启用`以打开存储库 `.github` 目录中的基本 dependabot.yml 配置文件；
* 添加`version`；
* 添加 `updates` 部分，并输入希望 Dependabot 监视的每个包管理器的条目；
* 对于每个包管理器，可使用：
  - `package-ecosystem` 指定包管理器。
  - `directory` 指定清单或其他定义文件的位置。
  - `schedule.interval` 指定检查新版本的频率。
* 在代码仓库的根目录创建`.github`目录；
* 创建 `dependabot.yml`文件并且存储到`.github`目录下。

示例 `dependabot.yml`

```
version: 2
updates:
  # Enable version updates for npm
  - package-ecosystem: "npm"
    # Look for `package.json` and `lock` files in the `root` directory
    directory: "/"
    # Check the npm registry for updates every day (weekdays)
    schedule:
      interval: "daily"
```

###### 配置 Renovate

* 在 Github 的 App 里面安装 Renovate app https://github.com/apps/renovate；
* 安装并配置完成后可以在PR中看到一个自动生成的PR `Configure Renovate`，这个PR中包含一个 `renovate.json` 文件，这个文件中包含了 renovate 的一些默认设定；
* 可以根据文档 (https://docs.renovatebot.com/configuration-options/) 添加或者修改适合自身项目的具体配置项;
* merge 此 PR；
* Renovate 会根据你配置的 schedule 时间去自动的扫描并生成包升级 PR 提醒

### 定期的重新部署维护阶段的应用

在应用处于维护阶段，如果不再有新的feature的引入，即使因为一些原因无法做定期的应用依赖升级，我们也建议你定期的重新部署这个应用，以应对平台等更底层的变化带来的部署失败的风险。定期部署可以确保你的应用在新的平台环境中也可以正常的部署，如果在周期性的部署过程中发现应用无法在新的环境部署，你也会有一个缓冲期来制订应对策略，而不是在平台完成升级之后的某一天，应用发生了问题才发现已经无法部署。

#### 优点：

1. 能够保证应用所需依赖是可获取且可用的。
   
    虽然我们的应用依赖的底层版本可以固定，也可以将部分依赖缓存到私有仓库，但一般来说，部分依赖还是需要我们从外部获取。如果长时间没有运行相关部署流程，我们无法保证我们的应用的依赖能够在需要部署过程中正常获取且可用。而定期重新部署应用，能够有效缩短我们的依赖获取未验证的窗口期。

2. 能够保证基础设施的变化不会影响我们的部署流程。
   
    现在的应用的基础设施在很多基于各类云厂商（AWS，Azure）或者开源软件(k8s,jenkins)。随着时间的变化，这些底层基础设施都有可能会有一定小版本的升级或者优化。如果长时间没有运行部署流程，我们无法得知在现有的基础设施下，是否能够正常的部署应用。

3. 能够平稳迭代基础设施平台
   
    我们使用的基础设施，是处于不断更新迭代过程中的。有一些变更我们可以从稳定性的角度出发，暂时不去升级这些版本。但是涉及到安全(logback安全漏洞),重大bug等情况，我们不得不升级这些版本以及调整我们的部署工具及部署策略。如果我们总是在遇到问题的时候再去调整这些东西，哪我们需要的调整的工作量就会相当的大。而通过定期重新部署，我们能在每一个周期，平滑的调整优化我们的部署工具及部署策略。

#### 缺点：

1. 增加维护成本
   
   定期的发布对我们系统的稳定性特别是做变更时的稳定性是很大的挑战。我们需要构建平滑高可用的发布流程，以及定期进行发布的人力资源。

2. 增加测试成本
   
   为了应对定期进行的发布行为，必须保障有完善的回归测试流程以及覆盖范围。
