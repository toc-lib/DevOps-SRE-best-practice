## 应用开发和部署

### 使用唯一性标识给镜像打标签

当生成容器镜像时，应当使用唯一性标识来给容器镜像打标签，唯一标识可以更好的标记当次生成的镜像，避免出现多个同名标签但不同的版本镜像被使用的情况。例如多次部署都使用了latest标签的镜像，可能因为拉取和缓存策略导致不同节点使用了不同版本的镜像，从而导致功能上的不一致，在这种情况下，并不能很方便的判断出某个节点部署的是哪一个版本。

唯一标识最好有一定的含义，不仅可以用来区分产物，还可以获取到本次构建的关键信息。比如git提交哈希等关联性比较强的标识。虽然时间戳也是一个唯一性比较强的标识，但是关联性相对较差，如果长度不足，也有一定的几率产生碰撞。可以考虑使用组合型标签，比如使用时间戳，build号，版本号等根据自己的需求来组合生成唯一标识，这样的标签本身就包含了很丰富的信息。

我们不建议单纯使用pipeline的build序号来作为镜像的标签，如果需要更换CI工具或者重建pipeline时，这个序号将会被重置而可能产生重复，除非在构建脚本中加入偏移量。而且不同的CI工具获取这个序号的方法也有所不同，对于迁移并不友好。虽然它的可追溯性看起来较好，但是单纯的Build序号和代码之间并没有直接的关联。

如果不是需要对外公开发布的镜像，并不建议对同一镜像打上多个不同标签。因为绝大部分的情况下，我们只会选用其中一个的标签在所有的地方使用，多个标签的实际意义并不会很大。


**唯一性标识的优点：**

1. 可以准确对应的到源代码具体版本，在溯源时可以对应到特定的提交而不是可能存在的多个提交。

2. 不需要使用SHA256等额外的信息来区分同一标签的不同版本。

**可能存在的缺点：**

1. 一些类型的唯一性标识可读性不是很高，比如git提交哈希。

2. 一些类型的标识受时间影响，不能使用同一命令获得一致结果，需要使用其他的方式来传递给后续阶段，比如时间戳。



**如何实施：**

```
GIT_HASH=$(git rev-parse HEAD)

docker build --rm -t "myapp:${GIT_HASH}" .
```

### 牲口模式

将需要大量、精心工作来维护的具有特定属性的服务实例（宠物模式），转变为可以被随时销毁和被替换的服务实例组（牲口模式），从而将更多资源和精力投入到更有价值的地方。配合自动化的基础设施，使服务实例以更快的速度演进，也使业务具备更多的弹性去应对市场变化。

为大家所熟知的“无状态”应用，是“牲口模式”的一种实现方式。“牲口模式”不等于“无状态”。

**宠物模式的弊端：**
1. 需要单独管理每一个服务实例，可能是手动安装、调试。
2. 服务实例只能垂直扩展（Scale-Up），昂贵且容易遇到瓶颈。
3. 应用部署笨重，难以自由地升级或者回滚应用，从而阻碍业务频繁变更。
4. 难以及时给服务实例打补丁、升级系统，从而承担不必要的安全风险。
5. 难以避免故障带来的服务失效和可能存在的数据损失的风险。

**牲口模式的收益：**
1. 支持自动故障切换。配合自动化基础设施，无需单独管理每个服务实例，节约管理成本和团队精力。
2. 支持自动水平伸缩（Scale-Out），配合自动化基础设施，从容应对业务峰谷，节约业务成本。
3. 支持随时被销毁或被替换，可以在不影响服务稳定性的前提下部署应用、进行系统升级或者打补丁。 

**如何实施：**
* “无状态”应用
1. API请求之间完全隔离，完成业务所需的数据均由客户端发送的请求提供。
2. 使用客户端Cookie、cache取代服务器端Session。对于一些敏感的临时数据，服务器端可以加密后交由客户端存储，在下个API请求时发回服务器解密使用。
3. 通过锁或者幂等性设计，使得应用能正确、快速、自动地解决对同一份数据的竞争而导致的流程异常、数据不一致等问题。例如，定时任务批量读取数据。


### 减少脚本/工具对环境的依赖

一般情况下，脚本都会或多或少的使用到一些外部工具。而我们的脚本很有可能会运行在不同的环境中，不同环境中提供的工具也会有版本和用法的差异。我们建议尽可能的减少所使用的工具对环境的依赖，尤其是系统不会默认安装的工具。另外在编写脚本的时候，也尽量避免使用只有某些版本才有的语法特性。这些情况都会导致管理脚本有可能出现一些不可预期的结果，我们建议使用容器化工具或者容器化环境管理工具如Batect来替代对应的需求。

**优点：**

1. 环境中只需要安装容器化工具即可。如：docker

    软件构建过程中可能会存在不同的服务需求不同，特别在微服务架构中。如前端使用 nodejs 开发，后端使用 java。则需要在 agent 中安装对应的编译软件，无疑增加了工具数量以及版本的维护成本。使用容器化工具的方式来管理，我们只需要确保 agent 有容器运行时，并将这个 image 做好保存，以后无论是前端还是后端，我们都能通过脚本来运行不同的容器工具如 gradle 镜像，就可以进行软件构建。使用这种方法，容器运行时的版本更新也可以做到一步到位。

2. 使本地运行与在线上环境中运行的软件一致，都是基于同一个 Dockerfile 或者同一个 image

    使用容器化的方式基于同一个 Dockerfile 构建出来的 artifact，我们可以将它运行在本地进行测试，通过后用同样的的 artifact 部署到线上环境。这样我们的安全测试以及业务测试结果都能进行保证。出现问题也可以使用本地的环境进行快速的排查，这样可以在一些权限控制严格，没有线上环境 debug 权限的情况下，进行一个快速的查错。

3. 对新人友好

    容器化的工具使得新人只需要知道进行构建的软件使用方式，不需要再去手动安装，配置工具。新人如果需要更新工具或者版本，可以快速的进行，无需关心每个工具的安装，升级方式，同时也避免了手动操作过程中出现的失误来 block CI 的运行。

4. 升级单个项目的环境变得非常容易

    使用容器化工具的情况下，脚本可以作为一个构建阶段的文档。通过统一的管理可以清除的知道在一个干净的环境中运行了哪些工具来完成构建工作。每个工具的版本信息，来源信息在一个脚本中就可以看到。当有升级需求的时候，可以快速的更改，无需关心工具背后的依赖问题，简单查看工具容器的文档，更改本版号就可以完成升级来进行测试。脚本在版本控制之下，测试失败回滚的代价也极小。

5. 解耦对 CI 工具或 agent 的依赖

    虽然在实际项目中我们更换CI工具的情况极少，但是如果做到使用容器化工具来进行软件的构建，我们的脚本就可以在不同的agent中来运行构建，将极大的减少维护成本，增加 agent 的利用率。不用再去手动维护每个 agent 的配置，只需要有相同的容器运行时配置，即可增强构建阶段的兼容性。由于使用容器，所以在真的发生 CI 工具切换的时候，我们也只需要使新的工具能运行脚本，agent 支持容器运行时，即可开始构建，大大减少了切换工具的额外工作量。

**缺点：**

1. 需要花费更多的流量

    由于在 agent 上没有安装构建所需要的各种软件，只有容器化工具(docker 等)，每次在运行任何的一条命令的时候都需要去容器仓库中获取对应的镜像。这无疑增加了 agent 在流量上的压力。

2. 运行过程需要的时间更长

    由于在 agent 上没有安装构建所需要的各种软件，每当要运行一个 task，都需要在 agent 上启动一个容器去运行对应，那么时间就会变为：下载 image + 启动容器 + task 执行，相比于直接在 agent 上直接运行 task 多出了“下载 image + 启动容器”的时间。

**如何实现：**

例：在容器中运行 terraform

在使用 terraform 时，不同版本之间的 terraform 并不兼容，那么如何保证所有人与 CI 都使用相同的 terraform 版本就是一个非常麻烦的事情。那么如果我们无论在 CI 还是本地都基于 docker 去运行 terraform 就可以解决这个问题。

```shell
#!/usr/bin/env bash

function terraform() {
  docker run --rm -it \
      -v $(pwd):/app -w /app \
      hashicorp/terraform:1.1.4 -c "$@"
}

terraform init
terraform plan && terraform apply
```

### 定期更新容器的基础镜像

    大多数基于容器的开发都始于基础镜像，在其上叠加了运行应用所必需的库、二进制文件和配置文件。基础镜像是大多数基于容器的开发工作流的起点。
    基础镜像通常由镜像维护者更新，以在镜像中包含新功能或对操作系统或框架的改进。打安全补丁是基础镜像更新的另一个常见原因。当基础镜像的源头发生更新，基础镜像的使用者必须更新基础镜像来让镜像包含关键修复，还必须重新构建每个应用程序镜像。

**定期更新容器基础镜像的收益：**
    Docker容器的镜像定期更新，所带来的好处和主机操作系统定期更新的好处类似。
1. 更新后的镜像通常带有可以增强应用程序安全性的补丁修复
2. 更新后的镜像通常包括可以提高应用程序性能的新功能或改进功能
3. 更新后的镜像通常会移除不必要的过时功能，这些功能如果存留可能会影响应用程序的流畅兼容性。
   除非有特定原因使用旧版本，否则都建议使用最新的容器依赖项和操作系统。
   由于已启用的容器中的镜像无法自我更新，因此必须使用其他方式来保持操作系统是最新的。

**如何实施：**
    在通过CI打包创建应用容器镜像时，可以通过指定Dockerfile中基础镜像的唯一标识来指定基础镜像的版本。当官方镜像推出新版本时，唯一标识将会改变，通过更新唯一标识将基础镜像指向最新版本。
    以下将给出示例，通过dfresh识别和更新基础镜像的方法。

* 安装dfresh
    下载二进制文件直接使用，或用以下命令
```
alias dfresh="docker run -ti --rm -v ~/.docker:/root/.docker -v `pwd`:/cwd realestate/dfresh"
```
* 检查基础镜像是否有更新
```
$ dfresh check Dockerfile
Dockerfile:1: bitnami/kubectl
  old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
  new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd
```
* 更新基础镜像
```
$ dfresh update Dockerfile
Dockerfile:1: bitnami/kubectl
  old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
  new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd
```
* 回退方法
    在遇到由于新基础镜像问题，需要回退基础镜像版本的情况时，将Dockerfile中基础镜像的SHA256改为上一个所使用的版本。


### 定期检查和升级依赖包
随着 Bug 修复、新功能的开发或者其他更新，我们应用的依赖包可能会过时。此时应用的依赖项越多，就越难跟上这些更新。过时的依赖包可能对安全构成威胁，并对性能产生负面影响。最新的软件包可防止漏洞，这意味着定期的依赖性检查和更新很重要。我们建议定期的对应用的依赖包做更新和安全检查，并升级到一个合适的版本。并且我们建议在应用的 pipeline 中加入这些检查任务，并在常规的开发过程中及时发现和升级。如果应用已经处于维护阶段，我们也建议定期执行这些检查并在需要的时候加以升级。

**定期检查和升级依赖包的优点:**

1. 定期升级依赖可以让应用的安全性和代码的可用性都有保障。  
2. 定期升级依赖会让解决依赖版本冲突和代码兼容性变得容易。  
3. 更新依赖项可以获得新的依赖项版本提供的所有性能改进。 这些改进可以有多种形式，例如修复以前的性能问题、改进了实现和算法等。  
4. 升级依赖项不仅可以改进现有功能，还可以使用到以前不存在的新功能。这些新功能最终可能让我们更好的实现自己应用的新功能。

**不定期检查和升级依赖包的弊端:**

1. 如果不及时更新依赖，将会使得产品难以维护，并可能导致开发人员的时间被常规的、无意义的工作占用。
2. 如果长期不更新依赖，会使应用面临无人问津的风险，之后在某一天需要进行改动的时候，面临大量的依赖包过期无法获取和版本升级造成的接口变化。这时就需要投入非常高的成本来让代码重新变得可用，甚至完全无法更新而变成遗留系统。
3. 当进行大的版本升级时，需要对应用程序进行更多的更改才能与较新的库兼容。这使得付出代价比及时更新依赖大得多。
4. 如果忽略升级依赖项，那么会面临无法在自己喜欢的平台上运行软件的可能。 例如，如果停止升级软件中的数据库驱动程序，那么将无法使用旧版本的数据库系统。这不仅会使应用变得过时且易受攻击，而且甚至可能无法从该数据库系统提供商处获得任何支持。  
5. 如果应用依赖于过时的依赖项而导致升级困难变得很难维护，会使得项目很难找到对这些旧技术有经验的人，甚至失去现有的维护者。

**如何实施:** 

#### 1. 手动检查

##### JS 篇

* npm-outdated & npm-update 
   * npm outdated：可以使用 `npm outdated` 获取当前需要升级的包的信息。
   * npm update: 会把所有的包升级到我们定义的需要的版本号。如果需要升级到最新的则需要使用@latest eg: `npm update cypress@latest`。

* npm-check-updates: 是一种更高级的检查工具
   * 首先需要全局安装 npm-check-updates: `npm install -g npm-check-updates `；
   * ncu: 检查需要升级的包信息，这里类似 `npm outdated`；
   * ncu --upgrade/ncu -u: 将所有的包升级到最新版本，即便是包含重大更改，也会进行更新。注意：更新完成后不会自动运行 npm install，所以还需要再手动执行来更新 package-lock.json。
   * ncu --interactive/ncu -i : interactive mode 安装某个包。

  小结：`npm-outdated` 和 `npm-check-updates`都可以用来做 `JS`项目的包检查、升级。

##### Java 篇

* 在 build.gradle中配置 `owasp.dependency-check`
* 执行` ./gradlew dependencyCheckAnalyze`
* 查看报告： `项目根目录>build>reports>dependency-check-report.html `

#### 2. CI Pipeline 集成

* npm-check-updates 与 Buildkite Pipeline 的集成

   由于 buildkite 没有官方插件支持 dependency-check。所以对于buildkite 推荐两种方式：

   * 自己开发对应功能的插件，然后集成到 pipeline 的 step 中；
   * 通过 docker-compose 的方式去运行对应的检查，将其在 pipeline 的 step 中去运行（如果需要可以添加 block 来强制检查 npm-check-updates 的结果）。

   ```
   ## Dockerfile
   FROM node:18.7.0
   WORKDIR app
   COPY ["package.json", "package-lock.json*", "./"]
   RUN npm install -g npm-check-updates
   ```

   ```
   ## docker-compose
   version: "2"

   services:
     node-version-check:
       build: .
       command: sh -c "ncu"
   ```

   ```
   ## auto/dependency-check.sh
   #!/usr/bin/env bash

   set -ex
   docker-compose run --rm node-version-check

   ```

   ```
   ## buildkite script
   steps
      - label: 'node version dependency-check'
        command: auto/dependency-check.sh
        agents:
          queue: 'xxxx'

      -  block: 'Please check node-version-check'
   ```

* jenkins pipeline 的集成：需要安装 dependency-check Plugin。步骤如下：
   1. 在 Jenkins Global Tool Configuration 安装 dependency-check；
   2. 在 Jenkins builder 配置已经安装好的 dependency-check；
   3. 在 Jenkins Publish 里配置读取 dependency-check 的 report ，通过对相关指标进行读取，设置阈值，配置构建失败或者警告等设置。

#### 3. 工具集成检查
如果项目 code 托管在 Github，我们可以使用 Dependabot 和 Renovate 工具和 Github 集成来做依赖检查。这两个工具都会做定期扫描，创建依赖版本升级的 PR。
##### 配置 Dependabot 进行版本更新

* 在 GitHub 的代码仓库的主页,找到代码仓库名称下的 `setting`；
* 在边栏的`安全性`部分中，单击`代码安全性和分析`；
* 在`代码安全和分析`下，在`Dependabot version updates`右侧，单击`启用`以打开存储库 `.github` 目录中的基本 dependabot.yml 配置文件；
* 添加`version`；
* 添加 `updates` 部分，并输入希望 Dependabot 监视的每个包管理器的条目；
* 对于每个包管理器，可使用：
   - `package-ecosystem` 指定包管理器。
   - `directory` 指定清单或其他定义文件的位置。
   - `schedule.interval` 指定检查新版本的频率。
* 在代码仓库的根目录创建`.github`目录；
* 创建 `dependabot.yml`文件并且存储到`.github`目录下。

示例 `dependabot.yml`

```
version: 2
updates:
  # Enable version updates for npm
  - package-ecosystem: "npm"
    # Look for `package.json` and `lock` files in the `root` directory
    directory: "/"
    # Check the npm registry for updates every day (weekdays)
    schedule:
      interval: "daily"
```

##### 配置 Renovate

* 在 Github 的 App 里面安装 Renovate app https://github.com/apps/renovate；
* 安装并配置完成后可以在PR中看到一个自动生成的PR `Configure Renovate`，这个PR中包含一个 `renovate.json` 文件，这个文件中包含了 renovate 的一些默认设定；
* 可以根据文档(https://docs.renovatebot.com/configuration-options/)添加或者修改适合自身项目的具体配置项;
* merge 此 PR；
* Renovate 会根据你配置的 schedule 时间去自动的扫描并生成包升级 PR 提醒
